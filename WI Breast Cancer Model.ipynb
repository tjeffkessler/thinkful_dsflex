{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Diagnostics\n",
    "\n",
    "Using breast cancer data from University of Wisconsin Hospitals, Madison, I will attempt to fit a supervised learning model to predict whether tumors are benign or malignant. The features are all integers between 1 and 10 that represent nine measurements of the tumor tissue. The class outcome variable gives a value of 2 for benign and 4 for malignant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample code number</th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample code number  Clump Thickness  Uniformity of Cell Size  \\\n",
       "0             1000025                5                        1   \n",
       "1             1002945                5                        4   \n",
       "2             1015425                3                        1   \n",
       "3             1016277                6                        8   \n",
       "4             1017023                4                        1   \n",
       "\n",
       "   Uniformity of Cell Shape  Marginal Adhesion  Single Epithelial Cell Size  \\\n",
       "0                         1                  1                            2   \n",
       "1                         4                  5                            7   \n",
       "2                         1                  1                            2   \n",
       "3                         8                  1                            3   \n",
       "4                         1                  3                            2   \n",
       "\n",
       "  Bare Nuclei  Bland Chromatin  Normal Nucleoli  Mitoses  Class  \n",
       "0           1                3                1        1      2  \n",
       "1          10                3                2        1      2  \n",
       "2           2                3                1        1      2  \n",
       "3           4                3                7        1      2  \n",
       "4           1                3                1        1      2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('wi_breast_cancer.txt')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample code number</th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1017122</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1018099</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1018561</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1033078</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1033078</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1035283</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1036172</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1041801</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1043999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1044572</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1047630</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1048672</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1049815</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1050670</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1050718</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sample code number  Clump Thickness  Uniformity of Cell Size  \\\n",
       "0              1000025                5                        1   \n",
       "1              1002945                5                        4   \n",
       "2              1015425                3                        1   \n",
       "3              1016277                6                        8   \n",
       "4              1017023                4                        1   \n",
       "5              1017122                8                       10   \n",
       "6              1018099                1                        1   \n",
       "7              1018561                2                        1   \n",
       "8              1033078                2                        1   \n",
       "9              1033078                4                        2   \n",
       "10             1035283                1                        1   \n",
       "11             1036172                2                        1   \n",
       "12             1041801                5                        3   \n",
       "13             1043999                1                        1   \n",
       "14             1044572                8                        7   \n",
       "15             1047630                7                        4   \n",
       "16             1048672                4                        1   \n",
       "17             1049815                4                        1   \n",
       "18             1050670               10                        7   \n",
       "19             1050718                6                        1   \n",
       "\n",
       "    Uniformity of Cell Shape  Marginal Adhesion  Single Epithelial Cell Size  \\\n",
       "0                          1                  1                            2   \n",
       "1                          4                  5                            7   \n",
       "2                          1                  1                            2   \n",
       "3                          8                  1                            3   \n",
       "4                          1                  3                            2   \n",
       "5                         10                  8                            7   \n",
       "6                          1                  1                            2   \n",
       "7                          2                  1                            2   \n",
       "8                          1                  1                            2   \n",
       "9                          1                  1                            2   \n",
       "10                         1                  1                            1   \n",
       "11                         1                  1                            2   \n",
       "12                         3                  3                            2   \n",
       "13                         1                  1                            2   \n",
       "14                         5                 10                            7   \n",
       "15                         6                  4                            6   \n",
       "16                         1                  1                            2   \n",
       "17                         1                  1                            2   \n",
       "18                         7                  6                            4   \n",
       "19                         1                  1                            2   \n",
       "\n",
       "   Bare Nuclei  Bland Chromatin  Normal Nucleoli  Mitoses  Class  \n",
       "0            1                3                1        1      0  \n",
       "1           10                3                2        1      0  \n",
       "2            2                3                1        1      0  \n",
       "3            4                3                7        1      0  \n",
       "4            1                3                1        1      0  \n",
       "5           10                9                7        1      1  \n",
       "6           10                3                1        1      0  \n",
       "7            1                3                1        1      0  \n",
       "8            1                1                1        5      0  \n",
       "9            1                2                1        1      0  \n",
       "10           1                3                1        1      0  \n",
       "11           1                2                1        1      0  \n",
       "12           3                4                4        1      1  \n",
       "13           3                3                1        1      0  \n",
       "14           9                5                5        4      1  \n",
       "15           1                4                3        1      1  \n",
       "16           1                2                1        1      0  \n",
       "17           1                3                1        1      0  \n",
       "18          10                4                1        2      1  \n",
       "19           1                3                1        1      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change class to 0 for benign, 1 for malignant\n",
    "df['Class'] = df['Class'].apply(lambda x: int((x//2)-1))\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample code number</th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.990000e+02</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.071704e+06</td>\n",
       "      <td>4.417740</td>\n",
       "      <td>3.134478</td>\n",
       "      <td>3.207439</td>\n",
       "      <td>2.806867</td>\n",
       "      <td>3.216023</td>\n",
       "      <td>3.437768</td>\n",
       "      <td>2.866953</td>\n",
       "      <td>1.589413</td>\n",
       "      <td>0.344778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.170957e+05</td>\n",
       "      <td>2.815741</td>\n",
       "      <td>3.051459</td>\n",
       "      <td>2.971913</td>\n",
       "      <td>2.855379</td>\n",
       "      <td>2.214300</td>\n",
       "      <td>2.438364</td>\n",
       "      <td>3.053634</td>\n",
       "      <td>1.715078</td>\n",
       "      <td>0.475636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.163400e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.706885e+05</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.171710e+06</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.238298e+06</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.345435e+07</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sample code number  Clump Thickness  Uniformity of Cell Size  \\\n",
       "count        6.990000e+02       699.000000               699.000000   \n",
       "mean         1.071704e+06         4.417740                 3.134478   \n",
       "std          6.170957e+05         2.815741                 3.051459   \n",
       "min          6.163400e+04         1.000000                 1.000000   \n",
       "25%          8.706885e+05         2.000000                 1.000000   \n",
       "50%          1.171710e+06         4.000000                 1.000000   \n",
       "75%          1.238298e+06         6.000000                 5.000000   \n",
       "max          1.345435e+07        10.000000                10.000000   \n",
       "\n",
       "       Uniformity of Cell Shape  Marginal Adhesion  \\\n",
       "count                699.000000         699.000000   \n",
       "mean                   3.207439           2.806867   \n",
       "std                    2.971913           2.855379   \n",
       "min                    1.000000           1.000000   \n",
       "25%                    1.000000           1.000000   \n",
       "50%                    1.000000           1.000000   \n",
       "75%                    5.000000           4.000000   \n",
       "max                   10.000000          10.000000   \n",
       "\n",
       "       Single Epithelial Cell Size  Bland Chromatin  Normal Nucleoli  \\\n",
       "count                   699.000000       699.000000       699.000000   \n",
       "mean                      3.216023         3.437768         2.866953   \n",
       "std                       2.214300         2.438364         3.053634   \n",
       "min                       1.000000         1.000000         1.000000   \n",
       "25%                       2.000000         2.000000         1.000000   \n",
       "50%                       2.000000         3.000000         1.000000   \n",
       "75%                       4.000000         5.000000         4.000000   \n",
       "max                      10.000000        10.000000        10.000000   \n",
       "\n",
       "          Mitoses       Class  \n",
       "count  699.000000  699.000000  \n",
       "mean     1.589413    0.344778  \n",
       "std      1.715078    0.475636  \n",
       "min      1.000000    0.000000  \n",
       "25%      1.000000    0.000000  \n",
       "50%      1.000000    0.000000  \n",
       "75%      1.000000    1.000000  \n",
       "max     10.000000    1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check mean and variance\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sample code number             0\n",
       "Clump Thickness                0\n",
       "Uniformity of Cell Size        0\n",
       "Uniformity of Cell Shape       0\n",
       "Marginal Adhesion              0\n",
       "Single Epithelial Cell Size    0\n",
       "Bare Nuclei                    0\n",
       "Bland Chromatin                0\n",
       "Normal Nucleoli                0\n",
       "Mitoses                        0\n",
       "Class                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "683"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows that are missing values for Bare Nuclei\n",
    "df = df.drop(df.index[np.where(df['Bare Nuclei']=='?')])\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    342.000000\n",
       "mean       0.461988\n",
       "std        0.499283\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        1.000000\n",
       "max        1.000000\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make feature set, outcome variable, and train/test split\n",
    "X = df.iloc[:, 1:-1]\n",
    "Y = df.iloc[:, -1]\n",
    "X_train, X_test = df.iloc[:342, 1:-1], df.iloc[342:, 1:-1]\n",
    "Y_train, Y_test = df.iloc[:342, -1], df.iloc[342:, -1]\n",
    "\n",
    "Y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    341.000000\n",
       "mean       0.237537\n",
       "std        0.426199\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        0.000000\n",
       "max        1.000000\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the mean of the train/test split\n",
    "Y_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5380116959064327\n"
     ]
    }
   ],
   "source": [
    "# Try a simple Naive Bayes model\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, Y_train)\n",
    "print(bnb.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[260,   0],\n",
       "       [ 81,   0]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pred = bnb.predict(X_test)\n",
    "\n",
    "confusion_matrix(Y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes \n",
    "The Naive Bayes classifier was not accurate. It ended up just choosing the dominant class. Let's try some other classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier(n_estimators=500, class_weight='balanced')\n",
    "rfc.fit(X_train, Y_train)\n",
    "rfc.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n",
    "The Random Forest Classifier looks like it has overfit, but let's run some cross-validation and do a little digging to see if that's the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94202899, 0.97101449, 0.95652174, 0.94202899, 0.98529412,\n",
       "       0.97058824, 0.98529412, 0.98529412, 0.97058824, 0.98507463])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(rfc, X, Y, cv=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[257,   3],\n",
       "       [  2,  79]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = rfc.predict(X_test)\n",
    "confusion_matrix(Y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The high level of accuracy still holds up in cross-validation. Still, this is a case where we should really try to reduce the number of false negatives to 0 if at all possible. Right now that number is at two, but that is on the test set. I want to see if this holds up when checking type II error in cross-validation, the model may be worth optimizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Set 1 Type I Error: 0.020513 Type II Error: 0.090047\n",
      "CV Set 2 Type I Error: 0.023316 Type II Error: 0.074419\n",
      "CV Set 3 Type I Error: 0.030227 Type II Error: 0.073892\n",
      "CV Set 4 Type I Error: 0.020513 Type II Error: 0.057416\n",
      "CV Set 5 Type I Error: 0.028278 Type II Error: 0.032864\n",
      "CV Set 6 Type I Error: 0.040302 Type II Error: 0.009756\n",
      "CV Set 7 Type I Error: 0.027848 Type II Error: 0.039024\n",
      "CV Set 8 Type I Error: 0.030848 Type II Error: 0.071429\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "cv = 8\n",
    "n = math.ceil(len(Y)/cv)\n",
    "for i in range(cv):\n",
    "    indices = np.random.randint(len(Y), size=n).tolist()\n",
    "    rfc.fit(X.iloc[indices], Y.iloc[indices])\n",
    "    pred = rfc.predict(X.drop(X.index[indices]))\n",
    "    cm = confusion_matrix(Y.drop(Y.index[indices]), pred)\n",
    "    print('CV Set {} Type I Error: {:2f} Type II Error: {:2f}'.format(i+1, \n",
    "                                                               (cm[0][1]/sum(cm[0])),\n",
    "                                                               (cm[1][0]/sum(cm[1]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type II error is higher than I would feel comfortable with for a cancer diagnostic model. I'm going to try a Gradient Boosting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.0\n",
      "Percent Type II errors: 0.0\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.011730205278592375\n",
      "Percent Type II errors: 0.011730205278592375\n"
     ]
    }
   ],
   "source": [
    "# We'll make 500 iterations, use 2-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(Y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(Y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Model\n",
    "\n",
    "The type II error is really low on this model, I would like to run a grid search on different parameters to optimize for minimal type II error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "total_recall = make_scorer(recall_score)\n",
    "\n",
    "param_dict = {'n_estimators': [100, 250, 500], 'learning_rate': [0.0001, 0.001, 0.01, 0.1, 0.25],\n",
    "              'max_depth': [2, 3, 4, None], 'loss': ['deviance', 'exponential'], \n",
    "              'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
    "\n",
    "gscv = GridSearchCV(clf, param_dict, scoring=total_recall, iid=False, cv=6)\n",
    "gscv.fit(X, Y)\n",
    "gscv.score(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[259,   1],\n",
       "       [  0,  81]], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = gscv.predict(X_test)\n",
    "confusion_matrix(Y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search \n",
    "After searching through many permutations of parameters, we got down to 0 false negatives in predicting the test set. Let's see exactly which parameters got us that level of accuracy and what the mean accuracy looked like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1,\n",
       " 'loss': 'deviance',\n",
       " 'max_depth': None,\n",
       " 'n_estimators': 500,\n",
       " 'subsample': 0.2}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeff\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Jeff\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Jeff\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Jeff\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Jeff\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Jeff\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split5_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Jeff\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Jeff\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.112769</td>\n",
       "      <td>0.020346</td>\n",
       "      <td>0.003664</td>\n",
       "      <td>4.710346e-04</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>deviance</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'learning_rate': 0.0001, 'loss': 'deviance', ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.112769</td>\n",
       "      <td>0.006401</td>\n",
       "      <td>0.003833</td>\n",
       "      <td>3.732517e-04</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>deviance</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'learning_rate': 0.0001, 'loss': 'deviance', ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.115101</td>\n",
       "      <td>0.003075</td>\n",
       "      <td>0.003998</td>\n",
       "      <td>5.462856e-07</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>deviance</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'learning_rate': 0.0001, 'loss': 'deviance', ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.125425</td>\n",
       "      <td>0.007818</td>\n",
       "      <td>0.003336</td>\n",
       "      <td>4.763335e-04</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>deviance</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'learning_rate': 0.0001, 'loss': 'deviance', ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.122770</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>0.003831</td>\n",
       "      <td>3.718725e-04</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>deviance</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.0001, 'loss': 'deviance', ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.112769      0.020346         0.003664    4.710346e-04   \n",
       "1       0.112769      0.006401         0.003833    3.732517e-04   \n",
       "2       0.115101      0.003075         0.003998    5.462856e-07   \n",
       "3       0.125425      0.007818         0.003336    4.763335e-04   \n",
       "4       0.122770      0.002597         0.003831    3.718725e-04   \n",
       "\n",
       "  param_learning_rate param_loss param_max_depth param_n_estimators  \\\n",
       "0              0.0001   deviance               2                100   \n",
       "1              0.0001   deviance               2                100   \n",
       "2              0.0001   deviance               2                100   \n",
       "3              0.0001   deviance               2                100   \n",
       "4              0.0001   deviance               2                100   \n",
       "\n",
       "  param_subsample                                             params  \\\n",
       "0             0.1  {'learning_rate': 0.0001, 'loss': 'deviance', ...   \n",
       "1             0.2  {'learning_rate': 0.0001, 'loss': 'deviance', ...   \n",
       "2             0.3  {'learning_rate': 0.0001, 'loss': 'deviance', ...   \n",
       "3             0.4  {'learning_rate': 0.0001, 'loss': 'deviance', ...   \n",
       "4             0.5  {'learning_rate': 0.0001, 'loss': 'deviance', ...   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0                0.0                0.0                0.0                0.0   \n",
       "1                0.0                0.0                0.0                0.0   \n",
       "2                0.0                0.0                0.0                0.0   \n",
       "3                0.0                0.0                0.0                0.0   \n",
       "4                0.0                0.0                0.0                0.0   \n",
       "\n",
       "   split4_test_score  split5_test_score  mean_test_score  std_test_score  \\\n",
       "0                0.0                0.0              0.0             0.0   \n",
       "1                0.0                0.0              0.0             0.0   \n",
       "2                0.0                0.0              0.0             0.0   \n",
       "3                0.0                0.0              0.0             0.0   \n",
       "4                0.0                0.0              0.0             0.0   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0              721                 0.0                 0.0   \n",
       "1              721                 0.0                 0.0   \n",
       "2              721                 0.0                 0.0   \n",
       "3              721                 0.0                 0.0   \n",
       "4              721                 0.0                 0.0   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0                 0.0                 0.0                 0.0   \n",
       "1                 0.0                 0.0                 0.0   \n",
       "2                 0.0                 0.0                 0.0   \n",
       "3                 0.0                 0.0                 0.0   \n",
       "4                 0.0                 0.0                 0.0   \n",
       "\n",
       "   split5_train_score  mean_train_score  std_train_score  \n",
       "0                 0.0               0.0              0.0  \n",
       "1                 0.0               0.0              0.0  \n",
       "2                 0.0               0.0              0.0  \n",
       "3                 0.0               0.0              0.0  \n",
       "4                 0.0               0.0              0.0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_score_df = pd.DataFrame(gscv.cv_results_)\n",
    "grid_score_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>0.481669</td>\n",
       "      <td>0.031258</td>\n",
       "      <td>0.006226</td>\n",
       "      <td>0.006580</td>\n",
       "      <td>0.1</td>\n",
       "      <td>exponential</td>\n",
       "      <td>4</td>\n",
       "      <td>250</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'exponential', ...</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.950</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.027639</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989950</td>\n",
       "      <td>0.994975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994975</td>\n",
       "      <td>0.994975</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.994979</td>\n",
       "      <td>0.002901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>0.281228</td>\n",
       "      <td>0.015624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>deviance</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'learning_rate': 0.25, 'loss': 'deviance', 'm...</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.031180</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>0.547171</td>\n",
       "      <td>0.018055</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.005823</td>\n",
       "      <td>0.25</td>\n",
       "      <td>exponential</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'learning_rate': 0.25, 'loss': 'exponential',...</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.031180</td>\n",
       "      <td>1</td>\n",
       "      <td>0.984925</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989950</td>\n",
       "      <td>0.994975</td>\n",
       "      <td>0.989950</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.991633</td>\n",
       "      <td>0.004735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>0.889538</td>\n",
       "      <td>0.308107</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>0.004476</td>\n",
       "      <td>0.1</td>\n",
       "      <td>exponential</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'exponential', ...</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.950</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.027639</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994975</td>\n",
       "      <td>0.989950</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994975</td>\n",
       "      <td>0.994975</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.994979</td>\n",
       "      <td>0.002901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>0.330705</td>\n",
       "      <td>0.016676</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.007366</td>\n",
       "      <td>0.25</td>\n",
       "      <td>exponential</td>\n",
       "      <td>None</td>\n",
       "      <td>250</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'learning_rate': 0.25, 'loss': 'exponential',...</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.031180</td>\n",
       "      <td>1</td>\n",
       "      <td>0.984925</td>\n",
       "      <td>0.974874</td>\n",
       "      <td>0.989950</td>\n",
       "      <td>0.989950</td>\n",
       "      <td>0.989950</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.984941</td>\n",
       "      <td>0.005788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>0.798966</td>\n",
       "      <td>0.180946</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>0.006733</td>\n",
       "      <td>0.1</td>\n",
       "      <td>exponential</td>\n",
       "      <td>None</td>\n",
       "      <td>500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'exponential', ...</td>\n",
       "      <td>0.900</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.034359</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979899</td>\n",
       "      <td>0.974874</td>\n",
       "      <td>0.984925</td>\n",
       "      <td>0.989950</td>\n",
       "      <td>0.984925</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.982429</td>\n",
       "      <td>0.004803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>0.860068</td>\n",
       "      <td>0.034614</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.005822</td>\n",
       "      <td>0.1</td>\n",
       "      <td>deviance</td>\n",
       "      <td>None</td>\n",
       "      <td>500</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.900</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.034359</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>1.018294</td>\n",
       "      <td>0.124042</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.005823</td>\n",
       "      <td>0.1</td>\n",
       "      <td>exponential</td>\n",
       "      <td>None</td>\n",
       "      <td>500</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'exponential', ...</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.031180</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994975</td>\n",
       "      <td>0.994975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994975</td>\n",
       "      <td>0.994975</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.996650</td>\n",
       "      <td>0.002369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>0.194470</td>\n",
       "      <td>0.011065</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>exponential</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'exponential', ...</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.950</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.031458</td>\n",
       "      <td>9</td>\n",
       "      <td>0.984925</td>\n",
       "      <td>0.989950</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989950</td>\n",
       "      <td>0.994975</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.992466</td>\n",
       "      <td>0.004813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>0.198951</td>\n",
       "      <td>0.010173</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.001490</td>\n",
       "      <td>0.25</td>\n",
       "      <td>exponential</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'learning_rate': 0.25, 'loss': 'exponential',...</td>\n",
       "      <td>0.900</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.950</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.034611</td>\n",
       "      <td>9</td>\n",
       "      <td>0.994975</td>\n",
       "      <td>0.994975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.998325</td>\n",
       "      <td>0.002369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>0.265608</td>\n",
       "      <td>0.018041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>exponential</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'learning_rate': 0.25, 'loss': 'exponential',...</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.040182</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>0.526300</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>exponential</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'exponential', ...</td>\n",
       "      <td>0.900</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.950</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.034611</td>\n",
       "      <td>9</td>\n",
       "      <td>0.994975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994975</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.996654</td>\n",
       "      <td>0.002366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>0.471319</td>\n",
       "      <td>0.024568</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.007366</td>\n",
       "      <td>0.25</td>\n",
       "      <td>exponential</td>\n",
       "      <td>None</td>\n",
       "      <td>250</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'learning_rate': 0.25, 'loss': 'exponential',...</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.950</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.031458</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>0.216493</td>\n",
       "      <td>0.048292</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>0.25</td>\n",
       "      <td>exponential</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'learning_rate': 0.25, 'loss': 'exponential',...</td>\n",
       "      <td>0.900</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.950</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.034611</td>\n",
       "      <td>9</td>\n",
       "      <td>0.989950</td>\n",
       "      <td>0.994975</td>\n",
       "      <td>0.994975</td>\n",
       "      <td>0.994975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.994979</td>\n",
       "      <td>0.002901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>1.044196</td>\n",
       "      <td>0.055174</td>\n",
       "      <td>0.005209</td>\n",
       "      <td>0.007367</td>\n",
       "      <td>0.1</td>\n",
       "      <td>exponential</td>\n",
       "      <td>None</td>\n",
       "      <td>500</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'exponential', ...</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.950</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.031458</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>0.713779</td>\n",
       "      <td>0.032428</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.1</td>\n",
       "      <td>deviance</td>\n",
       "      <td>None</td>\n",
       "      <td>250</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.031458</td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>0.634373</td>\n",
       "      <td>0.010209</td>\n",
       "      <td>0.006041</td>\n",
       "      <td>0.007003</td>\n",
       "      <td>0.1</td>\n",
       "      <td>exponential</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'exponential', ...</td>\n",
       "      <td>0.900</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>16</td>\n",
       "      <td>0.969849</td>\n",
       "      <td>0.984925</td>\n",
       "      <td>0.984925</td>\n",
       "      <td>0.989950</td>\n",
       "      <td>0.989950</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.984100</td>\n",
       "      <td>0.006754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>0.315758</td>\n",
       "      <td>0.010679</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.005823</td>\n",
       "      <td>0.25</td>\n",
       "      <td>exponential</td>\n",
       "      <td>3</td>\n",
       "      <td>250</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'learning_rate': 0.25, 'loss': 'exponential',...</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.031458</td>\n",
       "      <td>16</td>\n",
       "      <td>0.994975</td>\n",
       "      <td>0.994975</td>\n",
       "      <td>0.994975</td>\n",
       "      <td>0.994975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.995817</td>\n",
       "      <td>0.001871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>0.151030</td>\n",
       "      <td>0.007367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>exponential</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'exponential', ...</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.042696</td>\n",
       "      <td>16</td>\n",
       "      <td>0.974874</td>\n",
       "      <td>0.994975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989950</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.992466</td>\n",
       "      <td>0.008583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>0.390600</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.007365</td>\n",
       "      <td>0.1</td>\n",
       "      <td>deviance</td>\n",
       "      <td>4</td>\n",
       "      <td>250</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.042696</td>\n",
       "      <td>16</td>\n",
       "      <td>0.994975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999162</td>\n",
       "      <td>0.001873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>0.922121</td>\n",
       "      <td>0.028696</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.007366</td>\n",
       "      <td>0.1</td>\n",
       "      <td>deviance</td>\n",
       "      <td>None</td>\n",
       "      <td>500</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.031458</td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>0.604576</td>\n",
       "      <td>0.025371</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.005822</td>\n",
       "      <td>0.25</td>\n",
       "      <td>exponential</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'learning_rate': 0.25, 'loss': 'exponential',...</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.023936</td>\n",
       "      <td>16</td>\n",
       "      <td>0.994975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999162</td>\n",
       "      <td>0.001873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>0.330874</td>\n",
       "      <td>0.025035</td>\n",
       "      <td>0.002832</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>0.25</td>\n",
       "      <td>exponential</td>\n",
       "      <td>4</td>\n",
       "      <td>250</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'learning_rate': 0.25, 'loss': 'exponential',...</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.042696</td>\n",
       "      <td>16</td>\n",
       "      <td>0.979899</td>\n",
       "      <td>0.984925</td>\n",
       "      <td>0.994975</td>\n",
       "      <td>0.984925</td>\n",
       "      <td>0.979899</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.984104</td>\n",
       "      <td>0.005350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>0.575767</td>\n",
       "      <td>0.018767</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.005823</td>\n",
       "      <td>0.25</td>\n",
       "      <td>exponential</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'learning_rate': 0.25, 'loss': 'exponential',...</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.031458</td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>0.425879</td>\n",
       "      <td>0.099415</td>\n",
       "      <td>0.003604</td>\n",
       "      <td>0.005805</td>\n",
       "      <td>0.25</td>\n",
       "      <td>exponential</td>\n",
       "      <td>4</td>\n",
       "      <td>250</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'learning_rate': 0.25, 'loss': 'exponential',...</td>\n",
       "      <td>0.900</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994975</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.997492</td>\n",
       "      <td>0.002508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>0.190329</td>\n",
       "      <td>0.034968</td>\n",
       "      <td>0.003432</td>\n",
       "      <td>0.005741</td>\n",
       "      <td>0.25</td>\n",
       "      <td>deviance</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.25, 'loss': 'deviance', 'm...</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.962393</td>\n",
       "      <td>0.019025</td>\n",
       "      <td>26</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>0.687784</td>\n",
       "      <td>0.017761</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.007365</td>\n",
       "      <td>0.1</td>\n",
       "      <td>deviance</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.962393</td>\n",
       "      <td>0.019025</td>\n",
       "      <td>26</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>0.405690</td>\n",
       "      <td>0.014880</td>\n",
       "      <td>0.008811</td>\n",
       "      <td>0.007101</td>\n",
       "      <td>0.1</td>\n",
       "      <td>exponential</td>\n",
       "      <td>4</td>\n",
       "      <td>250</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'exponential', ...</td>\n",
       "      <td>0.900</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.950</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.037268</td>\n",
       "      <td>28</td>\n",
       "      <td>0.979899</td>\n",
       "      <td>0.989950</td>\n",
       "      <td>0.989950</td>\n",
       "      <td>0.989950</td>\n",
       "      <td>0.989950</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.988283</td>\n",
       "      <td>0.003749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>0.311204</td>\n",
       "      <td>0.006734</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.007365</td>\n",
       "      <td>0.1</td>\n",
       "      <td>exponential</td>\n",
       "      <td>3</td>\n",
       "      <td>250</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'exponential', ...</td>\n",
       "      <td>0.900</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.950</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.037268</td>\n",
       "      <td>28</td>\n",
       "      <td>0.964824</td>\n",
       "      <td>0.974874</td>\n",
       "      <td>0.984925</td>\n",
       "      <td>0.974874</td>\n",
       "      <td>0.979899</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.974066</td>\n",
       "      <td>0.007313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>0.577831</td>\n",
       "      <td>0.015638</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.005823</td>\n",
       "      <td>0.1</td>\n",
       "      <td>exponential</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'exponential', ...</td>\n",
       "      <td>0.900</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.950</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.037268</td>\n",
       "      <td>28</td>\n",
       "      <td>0.979899</td>\n",
       "      <td>0.984925</td>\n",
       "      <td>0.989950</td>\n",
       "      <td>0.984925</td>\n",
       "      <td>0.979899</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.983266</td>\n",
       "      <td>0.003731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "821        0.481669      0.031258         0.006226        0.006580   \n",
       "948        0.281228      0.015624         0.000000        0.000000   \n",
       "1044       0.547171      0.018055         0.002604        0.005823   \n",
       "829        0.889538      0.308107         0.004001        0.004476   \n",
       "1062       0.330705      0.016676         0.005208        0.007366   \n",
       "855        0.798966      0.180946         0.003011        0.006733   \n",
       "748        0.860068      0.034614         0.002604        0.005822   \n",
       "856        1.018294      0.124042         0.002604        0.005823   \n",
       "812        0.194470      0.011065         0.000666        0.001489   \n",
       "1029       0.198951      0.010173         0.000666        0.001490   \n",
       "1059       0.265608      0.018041         0.000000        0.000000   \n",
       "775        0.526300      0.007595         0.000000        0.000000   \n",
       "1064       0.471319      0.024568         0.010417        0.007366   \n",
       "1028       0.216493      0.048292         0.000666        0.001489   \n",
       "857        1.044196      0.055174         0.005209        0.007367   \n",
       "741        0.713779      0.032428         0.007813        0.007813   \n",
       "828        0.634373      0.010209         0.006041        0.007003   \n",
       "1009       0.315758      0.010679         0.002604        0.005823   \n",
       "785        0.151030      0.007367         0.000000        0.000000   \n",
       "712        0.390600      0.009014         0.005208        0.007365   \n",
       "749        0.922121      0.028696         0.010417        0.007366   \n",
       "1045       0.604576      0.025371         0.002604        0.005822   \n",
       "1035       0.330874      0.025035         0.002832        0.004016   \n",
       "1018       0.575767      0.018767         0.002604        0.005823   \n",
       "1036       0.425879      0.099415         0.003604        0.005805   \n",
       "925        0.190329      0.034968         0.003432        0.005741   \n",
       "721        0.687784      0.017761         0.005208        0.007365   \n",
       "820        0.405690      0.014880         0.008811        0.007101   \n",
       "792        0.311204      0.006734         0.005208        0.007365   \n",
       "801        0.577831      0.015638         0.002604        0.005823   \n",
       "\n",
       "     param_learning_rate   param_loss param_max_depth param_n_estimators  \\\n",
       "821                  0.1  exponential               4                250   \n",
       "948                 0.25     deviance            None                100   \n",
       "1044                0.25  exponential               4                500   \n",
       "829                  0.1  exponential               4                500   \n",
       "1062                0.25  exponential            None                250   \n",
       "855                  0.1  exponential            None                500   \n",
       "748                  0.1     deviance            None                500   \n",
       "856                  0.1  exponential            None                500   \n",
       "812                  0.1  exponential               4                100   \n",
       "1029                0.25  exponential               4                100   \n",
       "1059                0.25  exponential            None                100   \n",
       "775                  0.1  exponential               2                500   \n",
       "1064                0.25  exponential            None                250   \n",
       "1028                0.25  exponential               4                100   \n",
       "857                  0.1  exponential            None                500   \n",
       "741                  0.1     deviance            None                250   \n",
       "828                  0.1  exponential               4                500   \n",
       "1009                0.25  exponential               3                250   \n",
       "785                  0.1  exponential               3                100   \n",
       "712                  0.1     deviance               4                250   \n",
       "749                  0.1     deviance            None                500   \n",
       "1045                0.25  exponential               4                500   \n",
       "1035                0.25  exponential               4                250   \n",
       "1018                0.25  exponential               3                500   \n",
       "1036                0.25  exponential               4                250   \n",
       "925                 0.25     deviance               4                100   \n",
       "721                  0.1     deviance               4                500   \n",
       "820                  0.1  exponential               4                250   \n",
       "792                  0.1  exponential               3                250   \n",
       "801                  0.1  exponential               3                500   \n",
       "\n",
       "     param_subsample                                             params  \\\n",
       "821              0.3  {'learning_rate': 0.1, 'loss': 'exponential', ...   \n",
       "948              0.4  {'learning_rate': 0.25, 'loss': 'deviance', 'm...   \n",
       "1044             0.1  {'learning_rate': 0.25, 'loss': 'exponential',...   \n",
       "829              0.2  {'learning_rate': 0.1, 'loss': 'exponential', ...   \n",
       "1062             0.1  {'learning_rate': 0.25, 'loss': 'exponential',...   \n",
       "855              0.1  {'learning_rate': 0.1, 'loss': 'exponential', ...   \n",
       "748              0.2  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...   \n",
       "856              0.2  {'learning_rate': 0.1, 'loss': 'exponential', ...   \n",
       "812              0.3  {'learning_rate': 0.1, 'loss': 'exponential', ...   \n",
       "1029             0.4  {'learning_rate': 0.25, 'loss': 'exponential',...   \n",
       "1059             0.7  {'learning_rate': 0.25, 'loss': 'exponential',...   \n",
       "775              0.2  {'learning_rate': 0.1, 'loss': 'exponential', ...   \n",
       "1064             0.3  {'learning_rate': 0.25, 'loss': 'exponential',...   \n",
       "1028             0.3  {'learning_rate': 0.25, 'loss': 'exponential',...   \n",
       "857              0.3  {'learning_rate': 0.1, 'loss': 'exponential', ...   \n",
       "741              0.4  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...   \n",
       "828              0.1  {'learning_rate': 0.1, 'loss': 'exponential', ...   \n",
       "1009             0.2  {'learning_rate': 0.25, 'loss': 'exponential',...   \n",
       "785              0.3  {'learning_rate': 0.1, 'loss': 'exponential', ...   \n",
       "712              0.2  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...   \n",
       "749              0.3  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...   \n",
       "1045             0.2  {'learning_rate': 0.25, 'loss': 'exponential',...   \n",
       "1035             0.1  {'learning_rate': 0.25, 'loss': 'exponential',...   \n",
       "1018             0.2  {'learning_rate': 0.25, 'loss': 'exponential',...   \n",
       "1036             0.2  {'learning_rate': 0.25, 'loss': 'exponential',...   \n",
       "925              0.8  {'learning_rate': 0.25, 'loss': 'deviance', 'm...   \n",
       "721              0.2  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...   \n",
       "820              0.2  {'learning_rate': 0.1, 'loss': 'exponential', ...   \n",
       "792              0.1  {'learning_rate': 0.1, 'loss': 'exponential', ...   \n",
       "801              0.1  {'learning_rate': 0.1, 'loss': 'exponential', ...   \n",
       "\n",
       "      split0_test_score  split1_test_score  split2_test_score  \\\n",
       "821               0.925              1.000              0.975   \n",
       "948               0.925              1.000              0.975   \n",
       "1044              0.925              1.000              0.975   \n",
       "829               0.925              1.000              0.975   \n",
       "1062              0.900              0.975              0.975   \n",
       "855               0.900              1.000              0.975   \n",
       "748               0.900              1.000              0.975   \n",
       "856               0.925              1.000              0.975   \n",
       "812               0.925              1.000              0.975   \n",
       "1029              0.900              1.000              0.975   \n",
       "1059              0.875              0.975              0.975   \n",
       "775               0.900              1.000              0.975   \n",
       "1064              0.925              1.000              0.975   \n",
       "1028              0.900              1.000              0.975   \n",
       "857               0.925              1.000              0.975   \n",
       "741               0.900              0.975              0.975   \n",
       "828               0.900              1.000              0.975   \n",
       "1009              0.900              0.975              0.975   \n",
       "785               0.875              1.000              0.975   \n",
       "712               0.875              1.000              0.975   \n",
       "749               0.900              0.975              0.975   \n",
       "1045              0.925              0.950              0.975   \n",
       "1035              0.875              1.000              0.975   \n",
       "1018              0.900              0.975              0.975   \n",
       "1036              0.900              1.000              0.975   \n",
       "925               0.925              0.975              0.975   \n",
       "721               0.925              0.975              0.975   \n",
       "820               0.900              1.000              0.975   \n",
       "792               0.900              1.000              0.975   \n",
       "801               0.900              1.000              0.975   \n",
       "\n",
       "      split3_test_score  split4_test_score  split5_test_score  \\\n",
       "821               0.950              0.950           1.000000   \n",
       "948               0.925              0.975           1.000000   \n",
       "1044              0.925              0.975           1.000000   \n",
       "829               0.950              0.950           1.000000   \n",
       "1062              0.975              0.975           1.000000   \n",
       "855               0.950              0.975           1.000000   \n",
       "748               0.950              0.975           1.000000   \n",
       "856               0.925              0.975           1.000000   \n",
       "812               0.925              0.950           1.000000   \n",
       "1029              0.950              0.950           1.000000   \n",
       "1059              0.975              0.975           1.000000   \n",
       "775               0.950              0.950           1.000000   \n",
       "1064              0.925              0.950           1.000000   \n",
       "1028              0.950              0.950           1.000000   \n",
       "857               0.925              0.950           1.000000   \n",
       "741               0.950              0.975           1.000000   \n",
       "828               0.925              0.975           1.000000   \n",
       "1009              0.950              0.975           1.000000   \n",
       "785               0.950              0.975           1.000000   \n",
       "712               0.950              0.975           1.000000   \n",
       "749               0.950              0.975           1.000000   \n",
       "1045              0.950              0.975           1.000000   \n",
       "1035              0.950              0.975           1.000000   \n",
       "1018              0.950              0.975           1.000000   \n",
       "1036              0.925              0.975           1.000000   \n",
       "925               0.950              0.975           0.974359   \n",
       "721               0.950              0.975           0.974359   \n",
       "820               0.925              0.950           1.000000   \n",
       "792               0.925              0.950           1.000000   \n",
       "801               0.925              0.950           1.000000   \n",
       "\n",
       "      mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "821          0.966667        0.027639                1            0.989950   \n",
       "948          0.966667        0.031180                1            1.000000   \n",
       "1044         0.966667        0.031180                1            0.984925   \n",
       "829          0.966667        0.027639                1            0.994975   \n",
       "1062         0.966667        0.031180                1            0.984925   \n",
       "855          0.966667        0.034359                1            0.979899   \n",
       "748          0.966667        0.034359                1            1.000000   \n",
       "856          0.966667        0.031180                1            0.994975   \n",
       "812          0.962500        0.031458                9            0.984925   \n",
       "1029         0.962500        0.034611                9            0.994975   \n",
       "1059         0.962500        0.040182                9            1.000000   \n",
       "775          0.962500        0.034611                9            0.994975   \n",
       "1064         0.962500        0.031458                9            1.000000   \n",
       "1028         0.962500        0.034611                9            0.989950   \n",
       "857          0.962500        0.031458                9            1.000000   \n",
       "741          0.962500        0.031458               16            1.000000   \n",
       "828          0.962500        0.037500               16            0.969849   \n",
       "1009         0.962500        0.031458               16            0.994975   \n",
       "785          0.962500        0.042696               16            0.974874   \n",
       "712          0.962500        0.042696               16            0.994975   \n",
       "749          0.962500        0.031458               16            1.000000   \n",
       "1045         0.962500        0.023936               16            0.994975   \n",
       "1035         0.962500        0.042696               16            0.979899   \n",
       "1018         0.962500        0.031458               16            1.000000   \n",
       "1036         0.962500        0.037500               16            1.000000   \n",
       "925          0.962393        0.019025               26            1.000000   \n",
       "721          0.962393        0.019025               26            1.000000   \n",
       "820          0.958333        0.037268               28            0.979899   \n",
       "792          0.958333        0.037268               28            0.964824   \n",
       "801          0.958333        0.037268               28            0.979899   \n",
       "\n",
       "      split1_train_score  split2_train_score  split3_train_score  \\\n",
       "821             0.994975            1.000000            0.994975   \n",
       "948             1.000000            1.000000            1.000000   \n",
       "1044            1.000000            0.989950            0.994975   \n",
       "829             0.989950            1.000000            0.994975   \n",
       "1062            0.974874            0.989950            0.989950   \n",
       "855             0.974874            0.984925            0.989950   \n",
       "748             1.000000            1.000000            1.000000   \n",
       "856             0.994975            1.000000            0.994975   \n",
       "812             0.989950            1.000000            0.989950   \n",
       "1029            0.994975            1.000000            1.000000   \n",
       "1059            1.000000            1.000000            1.000000   \n",
       "775             1.000000            0.994975            1.000000   \n",
       "1064            1.000000            1.000000            1.000000   \n",
       "1028            0.994975            0.994975            0.994975   \n",
       "857             1.000000            1.000000            1.000000   \n",
       "741             1.000000            1.000000            1.000000   \n",
       "828             0.984925            0.984925            0.989950   \n",
       "1009            0.994975            0.994975            0.994975   \n",
       "785             0.994975            1.000000            1.000000   \n",
       "712             1.000000            1.000000            1.000000   \n",
       "749             1.000000            1.000000            1.000000   \n",
       "1045            1.000000            1.000000            1.000000   \n",
       "1035            0.984925            0.994975            0.984925   \n",
       "1018            1.000000            1.000000            1.000000   \n",
       "1036            0.994975            1.000000            1.000000   \n",
       "925             1.000000            1.000000            1.000000   \n",
       "721             1.000000            1.000000            1.000000   \n",
       "820             0.989950            0.989950            0.989950   \n",
       "792             0.974874            0.984925            0.974874   \n",
       "801             0.984925            0.989950            0.984925   \n",
       "\n",
       "      split4_train_score  split5_train_score  mean_train_score  \\\n",
       "821             0.994975               0.995          0.994979   \n",
       "948             1.000000               1.000          1.000000   \n",
       "1044            0.989950               0.990          0.991633   \n",
       "829             0.994975               0.995          0.994979   \n",
       "1062            0.989950               0.980          0.984941   \n",
       "855             0.984925               0.980          0.982429   \n",
       "748             1.000000               1.000          1.000000   \n",
       "856             0.994975               1.000          0.996650   \n",
       "812             0.994975               0.995          0.992466   \n",
       "1029            1.000000               1.000          0.998325   \n",
       "1059            1.000000               1.000          1.000000   \n",
       "775             0.994975               0.995          0.996654   \n",
       "1064            1.000000               1.000          1.000000   \n",
       "1028            1.000000               0.995          0.994979   \n",
       "857             1.000000               1.000          1.000000   \n",
       "741             1.000000               1.000          1.000000   \n",
       "828             0.989950               0.985          0.984100   \n",
       "1009            1.000000               0.995          0.995817   \n",
       "785             0.989950               0.995          0.992466   \n",
       "712             1.000000               1.000          0.999162   \n",
       "749             1.000000               1.000          1.000000   \n",
       "1045            1.000000               1.000          0.999162   \n",
       "1035            0.979899               0.980          0.984104   \n",
       "1018            1.000000               1.000          1.000000   \n",
       "1036            0.994975               0.995          0.997492   \n",
       "925             1.000000               1.000          1.000000   \n",
       "721             1.000000               1.000          1.000000   \n",
       "820             0.989950               0.990          0.988283   \n",
       "792             0.979899               0.965          0.974066   \n",
       "801             0.979899               0.980          0.983266   \n",
       "\n",
       "      std_train_score  \n",
       "821          0.002901  \n",
       "948          0.000000  \n",
       "1044         0.004735  \n",
       "829          0.002901  \n",
       "1062         0.005788  \n",
       "855          0.004803  \n",
       "748          0.000000  \n",
       "856          0.002369  \n",
       "812          0.004813  \n",
       "1029         0.002369  \n",
       "1059         0.000000  \n",
       "775          0.002366  \n",
       "1064         0.000000  \n",
       "1028         0.002901  \n",
       "857          0.000000  \n",
       "741          0.000000  \n",
       "828          0.006754  \n",
       "1009         0.001871  \n",
       "785          0.008583  \n",
       "712          0.001873  \n",
       "749          0.000000  \n",
       "1045         0.001873  \n",
       "1035         0.005350  \n",
       "1018         0.000000  \n",
       "1036         0.002508  \n",
       "925          0.000000  \n",
       "721          0.000000  \n",
       "820          0.003749  \n",
       "792          0.007313  \n",
       "801          0.003731  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_columns=None\n",
    "grid_score_df = grid_score_df.sort_values('rank_test_score')\n",
    "grid_score_df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion \n",
    "While the predictions on the test set showed no false negatives, the cross-validaton test scores for the top ranked parameters averaged out to 97%. While that is good, this accuracy is based on the scoring for recall (tp/tp+fn), so that all the error is derived from the false negatives. I think the model would benefit from more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
